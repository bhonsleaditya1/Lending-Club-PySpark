{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lending-Club-XGBoost-1vR.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jINz_xWhnoi0",
        "UCx-uDP6n9hu",
        "cA15Jv4IoY4_"
      ],
      "authorship_tag": "ABX9TyNsOZlrfgzwckMlGjeehtxO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhonsleaditya1/Lending-Club-PySpark/blob/master/Lending_Club_XGBoost_1vR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jINz_xWhnoi0"
      },
      "source": [
        "#Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDomCXTWN9jv"
      },
      "source": [
        "!pip install -q bayesian-optimization\n",
        "!pip install -q scikit-optimize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCrejJw6Oe_p"
      },
      "source": [
        "import os,gc,re,matplotlib,joblib,ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection  import StratifiedKFold,train_test_split,cross_validate\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler,StandardScaler,LabelEncoder,LabelBinarizer\n",
        "from sklearn.metrics import roc_auc_score,auc,roc_curve,accuracy_score,classification_report,confusion_matrix,f1_score\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "import xgboost as xgb\n",
        "from scipy.stats import zscore\n",
        "from sklearn import model_selection \n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCx-uDP6n9hu"
      },
      "source": [
        "#Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gjnEYT6Ppq3"
      },
      "source": [
        "pdf = pd.read_csv('/content/drive/My Drive/Lending-Club/loanFinal.csv', header=0, escapechar='\\\\')\n",
        "dropcol = pd.read_csv('/content/drive/My Drive/Lending-Club/FinalDrop.csv',header=None)[0].to_list()\n",
        "dbindex = pd.read_csv('/content/drive/My Drive/Lending-Club/DBRemove.csv')\n",
        "pdf = pdf[pdf.amnt_left_per<=100]\n",
        "pdf = pdf.drop(dropcol,axis=1)\n",
        "pdf = pdf.drop(dbindex['index'].to_list())\n",
        "pdf = pdf.reset_index().drop('index',axis=1)\n",
        "pdf.count()\n",
        "pdf['year'] = pd.DatetimeIndex(pdf['issue_d']).year\n",
        "reg = pdf.select_dtypes(['float64']).columns\n",
        "clas = pdf.select_dtypes(['O']).columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26SlOFJRoDH9"
      },
      "source": [
        "#Pre-Process Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1S1UZ-9qNc3"
      },
      "source": [
        "##OneHotEncoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXBe4-6LPuf0"
      },
      "source": [
        "#OneHotEncoding 1 vs R \n",
        "pdf.loc[pdf['target']==2,'target']=0\n",
        "for i in clas:\n",
        "  if pdf[i].nunique()<25:\n",
        "    l = pd.get_dummies(pdf[i], prefix=i)\n",
        "    for j in l.columns:\n",
        "      pdf[j] = l[j]\n",
        "for i in clas:\n",
        "  pdf = pdf.drop(i,axis=1)\n",
        "pdf = pdf.rename(columns={'emp_length_< 1 year':'emp_length_less 1 year'})\n",
        "timetest = pdf[pdf.year==2016]\n",
        "train = pdf[pdf.year!=2016]\n",
        "timetest = timetest.drop(['year'],axis=1)\n",
        "train = train.drop(['year'],axis=1)\n",
        "y_timetest=pd.DataFrame()\n",
        "y_t = pd.DataFrame()\n",
        "y_timetest['target'] = timetest['target']\n",
        "y_t['target'] = train['target']\n",
        "timetest = timetest.drop('target',axis=1)\n",
        "train = train.drop('target',axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(train, y_t, random_state=1301, test_size=0.3)\n",
        "scale = StandardScaler()\n",
        "scale.fit(X_train)\n",
        "X_train = scale.transform(X_train)\n",
        "X_test = scale.transform(X_test)\n",
        "timetest = scale.transform(timetest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmSNuB8tyd0n"
      },
      "source": [
        "#From this Cell\n",
        "1.   1 is Class 1\n",
        "2.   0 is Rest\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDt2_ATAoR2V"
      },
      "source": [
        "#Training Base XGBoost Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGYw7NOmQlSE"
      },
      "source": [
        "def gini_eval(y_pred, dtrain):\n",
        "    y_true = dtrain.get_label()\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc-1\n",
        "    err = gini\n",
        "    return 'gini_err', err\n",
        "clf = xgb.XGBClassifier(tree_method='gpu_hist',objective='binary:logistic',num_boost_round=70,verbose_eval=False,n_jobs=-1)\n",
        "clf.fit(X_train,y_train['target'],eval_metric=gini_eval,eval_set=[(X_train,y_train['target']),(timetest,y_timetest['target'])],early_stopping_rounds=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0TQiRmV1T2M"
      },
      "source": [
        "#Recursive Feature Selection with CV "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G4ZWm0r1Syi"
      },
      "source": [
        "classifier = xgb.XGBClassifier(objective= 'binary:logistic',tree_method='gpu_hist')\n",
        "\n",
        "selector = RFECV(estimator=classifier,cv=StratifiedKFold(n_splits=5,random_state=1301, shuffle=True), scoring='f1_weighted')\n",
        "selector.fit(X_train.fillna(-999999), y_train)\n",
        "\n",
        "print('The optimal number of features is {}'.format(selector.n_features_))\n",
        "features = [f for f,s in zip(X_train.columns, selector.support_) if s]\n",
        "print('The selected features are:')\n",
        "print ('{}'.format(features))\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (accuracy)\")\n",
        "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)\n",
        "plt.savefig('feature_auc_nselected.png', bbox_inches='tight', pad_inches=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEB9kzOF1she"
      },
      "source": [
        "##!!!Uncomment **ONLY** when you want to use RFECV features!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPCsC2zl1coX"
      },
      "source": [
        "#X_train = X_train[features]\n",
        "#X_test = X_test[features]\n",
        "#timetest = timetest[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA15Jv4IoY4_"
      },
      "source": [
        "#Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne2j9NPjphb1"
      },
      "source": [
        "##Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDpHy4p_TYLd"
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#Converting the dataframe into XGBoostâ€™s Dmatrix object\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(timetest,label=y_timetest)\n",
        "watchlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "cvvalues = []\n",
        "evalsdict={}\n",
        "ginivalues=[]\n",
        "#Bayesian Optimization function for xgboost\n",
        "def gini_eval(y_pred, dtrain):\n",
        "    err=0\n",
        "    y_true = dtrain.get_label()\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    gini = 2*roc_auc -1\n",
        "    err=1-gini\n",
        "    gc.collect()\n",
        "    return 'gini_err', err\n",
        "#specify the parameters you want to tune as keyword arguments\n",
        "def bo_tune_xgb(max_depth,gamma,n_estimators,learning_rate,reg_alpha,scale_pos_weight,colsamplebytree,max_delta_step):\n",
        "  global cvvalues,ginivalues,X_train,y_train,timetest,y_timetest\n",
        "  dicct={}\n",
        "  params = {'max_depth': int(max_depth),\n",
        "          'gamma': gamma,\n",
        "          'n_estimators': int(n_estimators),\n",
        "          'learning_rate':learning_rate,\n",
        "          'subsample': 0.8,\n",
        "          'eta': 0.1,\n",
        "          'reg_alpha':reg_alpha,\n",
        "          'scale_pos_weight':scale_pos_weight,\n",
        "          'colsamplebytree':colsamplebytree,\n",
        "          'eval_metric': 'error',\n",
        "          'objective': 'binary:logistic',\n",
        "          'max_delta_step':max_delta_step,\n",
        "          'tree_method':'gpu_hist'\n",
        "          }\n",
        "  #Cross validating with the specified parameters in 5 folds and 70 iterations\n",
        "  #cv_result = xgb.cv(params, dtrain, num_boost_round=70, nfold=5,\n",
        "                     #feval=gini_eval\n",
        "                     #metrics='logloss')\n",
        "  clf = xgb.XGBClassifier(**params,n_jobs=-1)\n",
        "  clf.fit(X_train,y_train['target'],eval_metric=gini_eval,eval_set=[(X_train,y_train['target']),(X_test,y_test['target'])],early_stopping_rounds=50,verbose=False)\n",
        "  #Return the gini\n",
        "  cvvalues.append(clf.best_score)\n",
        "  return 1-clf.best_score\n",
        "\n",
        "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
        "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (3, 10),\n",
        "                                            'gamma': (0, 1),\n",
        "                                            'scale_pos_weight': (7,100),                                          \n",
        "                                            'n_estimators':(100,1000),\n",
        "                                            'reg_alpha': (0,1),\n",
        "                                            'learning_rate': (0.01,0.5),\n",
        "                                            'colsamplebytree':(0,1),\n",
        "                                            'max_delta_step':(0,1)\n",
        "                                            })\n",
        "\n",
        "#performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement\n",
        "xgb_bo.maximize(n_iter=5, init_points=5, acq='ei')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41ELqj8aokYu"
      },
      "source": [
        "### Saving all Parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMo5vI9oTrUL"
      },
      "source": [
        "pd.DataFrame.from_dict(xgb_bo.res).to_excel('/content/drive/My Drive/Lending-Club/1vR_Bayesian_XGB_params.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QedbAKm-ru-C"
      },
      "source": [
        "###Gini and f1 for above generated model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8v8Yn9PrtjB"
      },
      "source": [
        "gini={}\n",
        "gini_train={}\n",
        "gini_time={}\n",
        "f1={}\n",
        "f1_train={}\n",
        "f1_time={}\n",
        "p = pd.DataFrame.from_dict(xgb_bo.res)\n",
        "for i in range(10):\n",
        "  para=p['params'][i]\n",
        "  para['n_estimators']=int(para['n_estimators'])\n",
        "  para['max_depth']=int(para['max_depth'])\n",
        "  para['scale_pos_weight']=int(para['scale_pos_weight'])\n",
        "  para['objective'] = 'binary:logistic'\n",
        "  para['tree_method'] = 'gpu_hist'\n",
        "  #dtrain = xgb.DMatrix(X_train,label=y_train)\n",
        "  clf = xgb.XGBClassifier(**para).fit(X_train,y_train)\n",
        "  res = clf.predict_proba(X_test)\n",
        "  gini[i]=calc_gini(y_test,res,2)\n",
        "  res = clf.predict(X_test)\n",
        "  f1[i]=f1_score(y_test,res,average=None)\n",
        "  res = clf.predict_proba(X_train)\n",
        "  gini_train[i]=calc_gini(y_train,res,2)\n",
        "  res = clf.predict(X_train)\n",
        "  f1_train[i]=f1_score(y_train,res,average=None)\n",
        "  res = clf.predict_proba(timetest)\n",
        "  gini_time[i]=calc_gini(y_timetest,res,2)\n",
        "  res = clf.predict(timetest)\n",
        "  f1_time[i]=f1_score(y_timetest,res,average=None)\n",
        "  gc.collect()\n",
        "  #fscores = pd.DataFrame({'X': list(clf.get_fscore().keys()), 'Y': list(clf.get_fscore().values())})\n",
        "  #plt.figure(i)\n",
        "  #fscores.sort_values(by='Y')[:20].plot.bar(x='X')\n",
        "#result = clf.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix2E3rxfsnQt"
      },
      "source": [
        "###Compile Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQn495dXsCUp"
      },
      "source": [
        "#Training data\n",
        "gini_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd7cUICnsHFC"
      },
      "source": [
        "#Test data\n",
        "gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F01o8G8tsR0y"
      },
      "source": [
        "#Time data\n",
        "gini_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuxDXUV3sei-"
      },
      "source": [
        "#Training data\n",
        "f1_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILE1mAARsejb"
      },
      "source": [
        "#Test data\n",
        "f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqJj-j9tsekH"
      },
      "source": [
        "#Time data\n",
        "f1_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUgLZY99p2ZF"
      },
      "source": [
        "###Training and Saving Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMUA-QPmp5_P"
      },
      "source": [
        "para= xgb_bo.max['params']\n",
        "para['n_estimators']=int(para['n_estimators'])\n",
        "para['max_depth']=int(para['max_depth'])\n",
        "para['scale_pos_weight']=int(para['scale_pos_weight'])\n",
        "para['objective'] = 'binary:logistic'\n",
        "para['tree_method'] ='gpu_hist'\n",
        "clf = xgb.XGBClassifier(**para,n_jobs=-1)\n",
        "clf.fit(X_train,y_train['target'],eval_metric=gini_eval,eval_set=[(X_train,y_train['target']),(X_test,y_test['target'])],early_stopping_rounds=50,verbose=False)\n",
        "joblib.dump(clf, '/content/drive/My Drive/Lending-Club/Models/XGB_1_Bayesian_best.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zss39KXwo-w6"
      },
      "source": [
        "##RandomSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtwlmQfOo8Jj"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost as xgb\n",
        "bayes_cv_tuner = RandomizedSearchCV(estimator = xgb.XGBClassifier(\n",
        "                                n_jobs = -1,\n",
        "                                objective = 'binary:logistic',\n",
        "                                learning_rate = 0.08,\n",
        "                                silent=1,\n",
        "                                n_estimators = 1000,\n",
        "                                tree_method='gpu_hist',                                \n",
        "                                early_stopping_rounds=50\n",
        "                                ),\n",
        "    param_distributions = {\n",
        "        'max_depth': (6, 8),\n",
        "        'max_delta_step': (0, 20),\n",
        "        'subsample': (0.01, 1.0, 'uniform'),\n",
        "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
        "        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
        "        'reg_lambda': (1e-2, 1000, 'log-uniform'),\n",
        "        'reg_alpha': (1e-2, 1.0, 'log-uniform'),\n",
        "        'gamma': (1e-2, 0.5, 'log-uniform'),\n",
        "        'min_child_weight': (0, 20),\n",
        "        'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n",
        "        \n",
        "    },    \n",
        "    scoring = 'roc_auc',\n",
        "    cv = StratifiedKFold(\n",
        "        n_splits=5,\n",
        "        shuffle=True,\n",
        "        random_state=42),\n",
        "    n_jobs = 8,\n",
        "    n_iter = 300,   \n",
        "    verbose = 500,\n",
        "    refit = True,\n",
        "    random_state = 12345)\n",
        "\n",
        "#Saving all results\n",
        "def status_print(optim_result):\n",
        "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
        "    # Get all the models tested so far in DataFrame format\n",
        "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
        "    # Get current parameters and the best parameters    \n",
        "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
        "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
        "        len(all_models),\n",
        "        np.round(bayes_cv_tuner.best_score_, 4),\n",
        "        bayes_cv_tuner.best_params_\n",
        "    )) \n",
        "    # Save all model results\n",
        "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
        "    all_models.to_csv(clf_name + \"1vR_Random_cv_results.csv\")\n",
        "\n",
        "#Best model\n",
        "result = bayes_cv_tuner.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR3b0lfbqhOV"
      },
      "source": [
        "#Analysing Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOAh847ct2Vb"
      },
      "source": [
        "##Input Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0_GJyDNtwT0"
      },
      "source": [
        "model = #input the model you want to analyse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP95hnrZqmVk"
      },
      "source": [
        "##Percentile f1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v51shqAlqgNb"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "res = model.predict_proba(X_train)\n",
        "th1=1-(y_train.target==0).sum()/y_train.target.count()*1\n",
        "th2=1-(y_train.target==1).sum()/y_train.target.count()*1\n",
        "c1=pd.DataFrame(res[:,0])\n",
        "c2=pd.DataFrame(res[:,1])\n",
        "print(f1_score(np.where(c1>c1.quantile(th1),1,0),np.where(y_train==0,1,0)))\n",
        "print(f1_score(np.where(c2>c2.quantile(th2),1,0),np.where(y_train==1,1,0)))\n",
        "res = model.predict_proba(X_test)\n",
        "th1=1-(y_test.target==0).sum()/y_test.target.count()*1\n",
        "th2=1-(y_test.target==1).sum()/y_test.target.count()*1\n",
        "c1=pd.DataFrame(res[:,0])\n",
        "c2=pd.DataFrame(res[:,1])\n",
        "print(f1_score(np.where(c1>c1.quantile(th1),1,0),np.where(y_test==0,1,0)))\n",
        "print(f1_score(np.where(c2>c2.quantile(th2),1,0),np.where(y_test==1,1,0)))\n",
        "res = model.predict_proba(timetest)\n",
        "th1=1-(y_timetest.target==0).sum()/y_timetest.target.count()*1\n",
        "th2=1-(y_timetest.target==1).sum()/y_timetest.target.count()*1\n",
        "c1=pd.DataFrame(res[:,0])\n",
        "c2=pd.DataFrame(res[:,1])\n",
        "print(f1_score(np.where(c1>c1.quantile(th1),1,0),np.where(y_timetest==0,1,0)))\n",
        "print(f1_score(np.where(c2>c2.quantile(th2),1,0),np.where(y_timetest==1,1,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2GTIG6Iqxf0"
      },
      "source": [
        "##Gini per Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrezJ1liqsfS"
      },
      "source": [
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "gini =0\n",
        "#No of classes is j\n",
        "j=2\n",
        "y_predtrain=model.predict_proba(X_train)\n",
        "y_pred=model.predict_proba(X_test)\n",
        "y_predtime=model.predict_proba(timetest)\n",
        "drop_enc = OneHotEncoder().fit(pd.DataFrame(y_test))\n",
        "y_gini = drop_enc.transform(pd.DataFrame(y_test)).toarray()\n",
        "drop_enc = OneHotEncoder().fit(pd.DataFrame(y_timetest))\n",
        "y_ginitime = drop_enc.transform(pd.DataFrame(y_timetest)).toarray()\n",
        "drop_enc = OneHotEncoder().fit(pd.DataFrame(y_train))\n",
        "y_ginitrain = drop_enc.transform(pd.DataFrame(y_train)).toarray()\n",
        "for i in range(j):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_ginitrain[:, i], y_predtrain[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    print(2*roc_auc[i]-1)\n",
        "for i in range(j):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_gini[:, i], y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    print(2*roc_auc[i]-1)\n",
        "for i in range(j):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_ginitime[:, i], y_predtime[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "    print(2*roc_auc[i]-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9_7rgRMq8y-"
      },
      "source": [
        "##Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0_DuBAq7pC"
      },
      "source": [
        "print(accuracy_score(y_train,model.predict(X_train)))\n",
        "print(accuracy_score(y_test,model.predict(X_test)))\n",
        "print(accuracy_score(y_timetest,model.predict(timetest)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcSh-DIgtVA-"
      },
      "source": [
        "##Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkFkQDE2tS5S"
      },
      "source": [
        "y_predtrain = model.predict(X_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_predtime = model.predict(timetest)\n",
        "print(classification_report(y_train, y_predtrain))\n",
        "print(classification_report(y_test, y_pred))  \n",
        "print(classification_report(y_timetest, y_predtime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yvKrgV6s-7p"
      },
      "source": [
        "#Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpuN5OoWt9Uy"
      },
      "source": [
        "##Input Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLbwKYg4t9VE"
      },
      "source": [
        "model_f = #input the model you want to find feature Importance\n",
        "model_name = #input model name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmQay1EIupMC"
      },
      "source": [
        "##Excel of Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKbFbQB4s90J"
      },
      "source": [
        "pd.DataFrame(dict(zip(X_train,model_f.feature_importances_)).items()).to_excel(str(model_name)+'_1vR_feature_imp.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}